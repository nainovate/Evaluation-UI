{
  "dashboardStats": {
    "totalEvaluations": 4,
    "activeEvaluations": 2,
    "completedEvaluations": 1,
    "failedEvaluations": 1,
    "averageSuccessRate": 75
  },
  "evaluationRuns": [
    {
      "id": "eval-001",
      "name": "Customer Support Evaluation",
      "deployment": "Claude-3.5 Sonnet",
      "organization": "Nainovate",
      "status": "in-progress",
      "createdAt": "2025-06-30T10:00:00Z",
      "totalTasks": 2400,
      "completedTasks": 1800,
      "failedTasks": 0,
      "progress": 75,
      "description": "Comprehensive evaluation of customer support responses",
      "model": "Claude-3.5 Sonnet",
      "dataset": "Customer Support Conversations v2",
      "metrics": ["Answer Relevancy", "Faithfulness"],
      "tags": ["customer-service", "quality-assessment"],
      "owner": "team@company.com"
    },
    {
      "id": "eval-002", 
      "name": "Content Quality Assessment",
      "deployment": "GPT-4 Turbo",
      "organization": "Nainovate",
      "status": "pending",
      "createdAt": "2025-06-30T08:00:00Z",
      "totalTasks": 1800,
      "completedTasks": 0,
      "failedTasks": 0,
      "progress": 0,
      "description": "Evaluating content generation quality and relevance",
      "model": "GPT-4 Turbo",
      "dataset": "Content Generation Benchmark",
      "tags": ["content", "generation"]
    },
    {
      "id": "eval-003",
      "name": "Medical QA Evaluation",
      "deployment": "Claude-3 Haiku",
      "organization": "Nainovate",
      "status": "in-progress",
      "createdAt": "2025-06-29T14:00:00Z",
      "totalTasks": 3200,
      "completedTasks": 2240,
      "failedTasks": 15,
      "progress": 70,
      "description": "Medical question-answering accuracy assessment",
      "model": "Claude-3 Haiku",
      "dataset": "Medical QA Dataset v3",
      "tags": ["medical", "qa", "healthcare"]
    },
    {
      "id": "eval-004",
      "name": "Code Review Analysis",
      "deployment": "GPT-4",
      "organization": "Nainovate",
      "status": "completed",
      "createdAt": "2025-06-28T09:00:00Z",
      "completedAt": "2025-06-28T14:30:00Z",
      "totalTasks": 1500,
      "completedTasks": 1500,
      "failedTasks": 0,
      "progress": 100,
      "description": "Code quality evaluation and suggestions",
      "model": "GPT-4",
      "dataset": "Code Review Dataset",
      "tags": ["code", "review", "quality"]
    }
  ],
  "evaluationTasks": [
    {
      "id": "task-1",
      "evaluationId": "eval-001",
      "name": "Product Inquiry Response",
      "status": "completed",
      "progress": 100,
      "startedAt": "2025-06-30T10:05:00Z",
      "completedAt": "2025-06-30T10:25:00Z"
    },
    {
      "id": "task-2",
      "evaluationId": "eval-001",
      "name": "Technical Support Query",
      "status": "failed",
      "progress": 0,
      "startedAt": "2025-06-30T10:30:00Z",
      "error": "Request timeout"
    },
    {
      "id": "task-3",
      "evaluationId": "eval-003",
      "name": "Medical Diagnosis Question",
      "status": "running",
      "progress": 65,
      "startedAt": "2025-06-29T14:20:00Z"
    },
    {
      "id": "task-4",
      "evaluationId": "eval-003",
      "name": "Treatment Recommendation",
      "status": "pending",
      "progress": 0,
      "startedAt": "2025-06-29T14:25:00Z"
    }
  ],
  "organizations": [
    {
      "id": "org-1",
      "name": "Nainovate",
      "description": "AI evaluation platform",
      "activeDeployments": 5,
      "totalEvaluations": 127
    },
    {
      "id": "org-2",
      "name": "TechFlow Inc",
      "description": "Enterprise software solutions",
      "activeDeployments": 3,
      "totalEvaluations": 89
    },
    {
      "id": "org-3",
      "name": "Healthcare AI Corp",
      "description": "Medical AI solutions",
      "activeDeployments": 4,
      "totalEvaluations": 203
    }
  ],
  "deployments": [
    {
      "id": "deploy-1",
      "name": "Claude-3.5 Sonnet",
      "description": "Claude 3.5 Sonnet deployment",
      "version": "v1.0.0",
      "endpoint": "https://api.anthropic.com/v1/messages",
      "status": "active",
      "lastUpdated": "2025-06-30T10:30:00Z",
      "organization": "org-1",
      "responseTime": 120,
      "uptime": 99.9
    },
    {
      "id": "deploy-2",
      "name": "GPT-4 Turbo",
      "description": "OpenAI GPT-4 Turbo deployment",
      "version": "v2.1.3",
      "endpoint": "https://api.openai.com/v1/chat/completions",
      "status": "active",
      "lastUpdated": "2025-06-30T09:15:00Z",
      "organization": "org-1",
      "responseTime": 95,
      "uptime": 99.8
    },
    {
      "id": "deploy-3",
      "name": "Claude-3 Haiku",
      "description": "Claude 3 Haiku deployment",
      "version": "v1.2.1",
      "endpoint": "https://api.anthropic.com/v1/messages",
      "status": "active",
      "lastUpdated": "2025-06-29T16:45:00Z",
      "organization": "org-3",
      "responseTime": 85,
      "uptime": 99.7
    }
  ],
  "evaluationDatasets": [
    {
      "id": "dataset-001",
      "uid": "dataset-001",
      "name": "Customer Support Q&A",
      "description": "Question-answer pairs for customer support bot evaluation",
      "size": 1024000,
      "status": "valid",
      "columns": ["input", "expected_output", "category"],
      "rows": 1200,
      "uploadedAt": "2025-06-25T14:30:00Z",
      "taskType": "Question Answering",
      "tags": ["customer_support", "qa", "evaluation"],
      "format": "CSV",
      "filePath": "/uploads/datasets/customer_support_qa.csv",
      "originalFileName": "customer_support_qa.csv"
    },
    {
      "id": "dataset-002",
      "uid": "dataset-002",
      "name": "Medical QA Dataset v3",
      "description": "Medical questions with validated answers",
      "size": 2048000,
      "status": "valid",
      "columns": ["question", "expected_answer", "medical_field", "difficulty"],
      "rows": 3200,
      "uploadedAt": "2025-06-20T09:15:00Z",
      "taskType": "Question Answering",
      "tags": ["medical", "healthcare", "qa"],
      "format": "JSON",
      "filePath": "/uploads/datasets/medical_qa_v3.json",
      "originalFileName": "medical_qa_dataset_v3.json"
    },
    {
      "id": "dataset-003",
      "uid": "dataset-003",
      "name": "Content Generation Benchmark",
      "description": "Content generation prompts and expected outputs",
      "size": 512000,
      "status": "valid",
      "columns": ["prompt", "expected_content", "content_type", "length"],
      "rows": 1800,
      "uploadedAt": "2025-06-18T11:45:00Z",
      "taskType": "Text Generation",
      "tags": ["content", "generation", "benchmark"],
      "format": "CSV",
      "filePath": "/uploads/datasets/content_generation.csv",
      "originalFileName": "content_generation_benchmark.csv"
    }
  ]
}