{
  "datasets": [
    {
      "id": "eval_dataset_001",
      "uid": "eval_dataset_001",
      "name": "Customer Support Q&A",
      "description": "Question-answer pairs for customer support bot evaluation",
      "size": 1024000,
      "status": "valid",
      "columns": ["input", "expected_output", "category"],
      "rows": 1200,
      "uploadedAt": "2024-01-12T14:30:00Z",
      "taskType": "Question Answering",
      "tags": ["customer_support", "qa", "evaluation"],
      "format": "CSV",
      "filePath": "/uploads/datasets/customer_support_qa.csv",
      "originalFileName": "customer_support_qa.csv"
    },
    {
      "id": "eval_dataset_002",
      "uid": "eval_dataset_002",
      "name": "Code Generation Test Set",
      "description": "Programming problems with expected solutions",
      "size": 2048000,
      "status": "valid",
      "columns": ["problem_description", "expected_code", "difficulty", "language"],
      "rows": 500,
      "uploadedAt": "2024-01-13T09:15:00Z",
      "taskType": "Code Generation",
      "tags": ["code", "programming", "evaluation"],
      "format": "JSON",
      "filePath": "/uploads/datasets/code_generation.json",
      "originalFileName": "code_generation_test.json"
    },
    {
      "id": "eval_dataset_003",
      "uid": "eval_dataset_003",
      "name": "Sentiment Analysis Dataset",
      "description": "Text samples with sentiment labels",
      "size": 512000,
      "status": "valid",
      "columns": ["text", "sentiment", "confidence"],
      "rows": 2000,
      "uploadedAt": "2024-01-14T11:45:00Z",
      "taskType": "Text Classification",
      "tags": ["sentiment", "classification", "evaluation"],
      "format": "CSV",
      "filePath": "/uploads/datasets/sentiment_analysis.csv",
      "originalFileName": "sentiment_data.csv"
    },
    {
      "id": "eval_dataset_004",
      "uid": "eval_dataset_004",
      "name": "Content Generation Benchmark",
      "description": "Creative content generation evaluation with human ratings",
      "size": 1536000,
      "status": "valid",
      "columns": ["prompt", "expected_output", "creativity_score", "coherence_score"],
      "rows": 750,
      "uploadedAt": "2024-01-14T16:20:00Z",
      "taskType": "Content Generation",
      "tags": ["content", "creative", "evaluation"],
      "format": "JSON",
      "filePath": "/uploads/datasets/content_generation.json",
      "originalFileName": "content_benchmark.json"
    },
    {
      "id": "eval_dataset_005",
      "uid": "eval_dataset_005",
      "name": "Multi-turn Conversation Test",
      "description": "Conversational AI evaluation with context awareness",
      "size": 3072000,
      "status": "valid",
      "columns": ["conversation_history", "question", "expected_answer", "turn_id"],
      "rows": 800,
      "uploadedAt": "2024-01-15T13:10:00Z",
      "taskType": "Conversational QA",
      "tags": ["conversational", "multi-turn", "evaluation"],
      "format": "YAML",
      "filePath": "/uploads/datasets/conversation_test.yaml",
      "originalFileName": "conversation_eval.yaml"
    },
    {
      "id": "eval_dataset_006",
      "uid": "eval_dataset_006",
      "name": "RAG Document Retrieval",
      "description": "Retrieval-Augmented Generation evaluation with document relevance",
      "size": 2560000,
      "status": "valid",
      "columns": ["query", "retrieved_documents", "expected_answer", "generated_answer", "ground_truth_docs"],
      "rows": 300,
      "uploadedAt": "2024-01-16T09:30:00Z",
      "taskType": "Retrieval (RAG)",
      "tags": ["rag", "retrieval", "evaluation"],
      "format": "YAML",
      "filePath": "/uploads/datasets/rag_evaluation.yaml",
      "originalFileName": "rag_test_data.yaml"
    },
    {
      "id": "eval_dataset_007",
      "uid": "eval_dataset_007",
      "name": "Creative Writing Evaluation",
      "description": "Open-ended generation evaluation with creativity and safety assessments",
      "size": 1920000,
      "status": "valid",
      "columns": ["prompt", "generated_output", "reference_output", "feedback", "toxicity_flag"],
      "rows": 400,
      "uploadedAt": "2024-01-17T15:20:00Z",
      "taskType": "Open-ended Generation",
      "tags": ["generation", "creative", "evaluation"],
      "format": "YAML",
      "filePath": "/uploads/datasets/creative_writing.yaml",
      "originalFileName": "creative_eval.yaml"
    },
    {
      "id": "eval_dataset_008",
      "uid": "eval_dataset_008",
      "name": "Technical Documentation Q&A",
      "description": "Technical documentation comprehension and question answering",
      "size": 4096000,
      "status": "processing",
      "columns": ["document_section", "question", "expected_answer", "difficulty"],
      "rows": 1500,
      "uploadedAt": "2024-01-18T10:00:00Z",
      "taskType": "Question Answering",
      "tags": ["technical", "documentation", "evaluation"],
      "format": "CSV",
      "filePath": "/uploads/datasets/tech_docs_qa.csv",
      "originalFileName": "technical_qa.csv"
    }
  ]
}